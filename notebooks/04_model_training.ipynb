{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f151145",
   "metadata": {},
   "source": [
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4584878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib  # For saving models\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86c8e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 81963\n",
      "Hindi samples: 17123\n",
      "English samples: 64840\n",
      "\n",
      "Dataset shape: (81963, 3)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§Æ‡•ã‡§¶‡•Ä ‡§ï‡•á ‡§∂‡§æ‡§∏‡§® ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§ó‡§Ç‡§ó‡§æ ‡§ó‡§Ç‡§ó‡§æ ‡§®‡§¶‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡§π ‡§ñ‡§¨‡§∞ ‡§Ü‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§õ‡§µ‡§ø ‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü ‡§ú‡§∏‡•ç‡§ü‡§ø‡§® ‡§∏‡•Å‡§≤‡§ø‡§µ‡§æ‡§® ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§ó‡•Å‡§≤‡§æ‡§¨ ‡§ó‡•á‡§Ç‡§¶ ‡§µ‡§æ‡§≤ ‡§°‡•á ‡§®‡§æ‡§á‡§ü ‡§ü‡•á‡§∏‡•ç‡§ü ‡§Æ‡•à‡§ö ‡§ï‡§™‡•ç‡§§‡§æ ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•ã‡§∞‡§ø‡§Ø‡§æ ‡§∞‡•â‡§ï‡•á‡§ü ‡§™‡•ç‡§∞‡§ï‡•ç‡§∑‡•á‡§™‡§£ ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç 71 0 15 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§™‡§§‡§ø ‡§°‡•ã‡§®‡§æ‡§≤‡•ç‡§° ‡§ü‡•ç‡§∞‡§Æ‡•ç‡§™ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§•‡§Æ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§Æ‡•á‡§≤‡§æ‡§®...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  label language\n",
       "0  ‡§Æ‡•ã‡§¶‡•Ä ‡§ï‡•á ‡§∂‡§æ‡§∏‡§® ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§ó‡§Ç‡§ó‡§æ ‡§ó‡§Ç‡§ó‡§æ ‡§®‡§¶‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ...      1       hi\n",
       "1  ‡§Ø‡§π ‡§ñ‡§¨‡§∞ ‡§Ü‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§õ‡§µ‡§ø ‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü ‡§ú‡§∏‡•ç‡§ü‡§ø‡§® ‡§∏‡•Å‡§≤‡§ø‡§µ‡§æ‡§® ...      1       hi\n",
       "2  ‡§ó‡•Å‡§≤‡§æ‡§¨ ‡§ó‡•á‡§Ç‡§¶ ‡§µ‡§æ‡§≤ ‡§°‡•á ‡§®‡§æ‡§á‡§ü ‡§ü‡•á‡§∏‡•ç‡§ü ‡§Æ‡•à‡§ö ‡§ï‡§™‡•ç‡§§‡§æ ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï...      0       hi\n",
       "3  ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•ã‡§∞‡§ø‡§Ø‡§æ ‡§∞‡•â‡§ï‡•á‡§ü ‡§™‡•ç‡§∞‡§ï‡•ç‡§∑‡•á‡§™‡§£ ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç 71 0 15 0...      1       hi\n",
       "4  ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§™‡§§‡§ø ‡§°‡•ã‡§®‡§æ‡§≤‡•ç‡§° ‡§ü‡•ç‡§∞‡§Æ‡•ç‡§™ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§•‡§Æ ‡§Æ‡§π‡§ø‡§≤‡§æ ‡§Æ‡•á‡§≤‡§æ‡§®...      0       hi"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"../dataset/unified_cleaned_dataset.csv\")\n",
    "df = df.dropna(subset=['clean_text'])  # Final safety check\n",
    "\n",
    "# Display basic dataset information\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Hindi samples: {len(df[df['language']=='hi'])}\")\n",
    "print(f\"English samples: {len(df[df['language']=='en'])}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0008ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Distribution:\n",
      "label\n",
      "0    51382\n",
      "1    30581\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (%):\n",
      "label\n",
      "0    62.689262\n",
      "1    37.310738\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nLabel distribution (%):\")\n",
    "print(df['label'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867a11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 65570\n",
      "Testing set size: 16393\n"
     ]
    }
   ],
   "source": [
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "print(\"=\" * 60)\n",
    "print(\"TF-IDF VECTORIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,      # Limit to 20k most important features\n",
    "    ngram_range=(1, 2),      # Use unigrams and bigrams\n",
    "    min_df=5,                # Ignore terms appearing in < 5 documents\n",
    "    max_df=0.8,              # Ignore terms appearing in > 80% of documents\n",
    "    stop_words=None          # No stop words (dataset has Hindi + English)\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both sets\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Display vectorization results\n",
    "print(f\"\\nTraining set shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Test set shape: {X_test_tfidf.shape}\")\n",
    "print(f\"Number of features extracted: {X_train_tfidf.shape[1]}\")\n",
    "print(f\"Training set sparsity: {1 - (X_train_tfidf.nnz / (X_train_tfidf.shape[0] * X_train_tfidf.shape[1])):.2%}\")\n",
    "print(\"\\n‚úÖ TF-IDF vectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOGISTIC REGRESSION MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,           # Maximum iterations for convergence\n",
    "    random_state=42,         # For reproducibility\n",
    "    n_jobs=-1,               # Use all available processors\n",
    "    C=1.0,                   # Regularization strength\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOGISTIC REGRESSION EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"\\nüìä Overall Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Real (0)', 'Fake (1)'], digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"-\" * 60)\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"-\" * 60)\n",
    "print(cm)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Real', 'Fake'], \n",
    "            yticklabels=['Real', 'Fake'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Logistic Regression - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(lr_model, '../models/logistic_regression_tfidf.pkl')\n",
    "joblib.dump(tfidf, '../models/tfidf_vectorizer.pkl')\n",
    "print(\"\\n‚úÖ Model and vectorizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
